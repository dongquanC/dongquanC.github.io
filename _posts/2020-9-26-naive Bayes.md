---
# layout: page
title: 朴素贝叶斯
categories: [强调, 数据分析]
tags: [Python,算法,未完成]
# excerpt: 简介朴素贝叶斯算法原理
date: 2020-09-26
lastmod: 2020-09-26
math: true
comments: false
excerpt_separator:  '<!-- more -->'
# project: true
---

*该篇内容还未完成*，由于MathJax的原因，请转到[博客园](https://www.cnblogs.com/Kseven77/p/13735920.html).见谅！ 


<!-- more -->

本文所阐述的定义，若无特殊表明出处则皆源自于《概率论与数理统计（第四版）》
# 回顾

**样本空间**：我们将随机试验E的所以可能的结果组成的集合成为E的样本的样本空间，记为$S$.  
**随机事件**：一般，我们称试验E的样本空间S的子集为E的随机事件.  
**随机变量**：表示随机试验各种结果的实值单值函数[百度百科].设随机试验的样本空间为$S={e}$.$X=X(e)$是定义在样本空间S上的实值单值函数.称$X=X(e)$为随机变量.

**乘法定理**：设$P(A)>0$ 则有：
$$p(AB)=p(B|A)P(A).$$
**全概率公式**：设试验E的样本空间为S，A为E的事件，$B_1,B_2,...,B_n$为S的一个划分，且$P(B_i)>0 (i=0,1,2,3,...,n)$，则
$$P(A)=P(A|B_1)P(B_1)+P(A|B_2)P(B_2)+...+P(A|B_n)P(B_n).$$
**贝叶斯公式**：设试验E的样本空间为S，A为E的事件，$B_1,B_2,...,B_n$为S的一个划分，且$P(A)>0$，$P(B_i)>0 (i=0,1,2,3,...,n)$，则
$$\frac{P(B_i|A)=P(A|B_i)P(B_i)}{\sum_{j=1}^nP(A|B_i)P(B_i)},i=1,2,3,...,n.$$

# 数据集定义
设输入空间$\chi \subseteq R^n$为$n$维向量的集合，输出空间为类标记集合$\Upsilon=\{ c_1,c_2,...,c_k\}$，输入为特征向量$x \subseteq \chi$，输出为类标记$y \subseteq \Upsilon$，X是定义在输入空间上的随机变量，Y是定义在输出空间的随机变量。$P(X,Y)$是X和Y的联合分布概率。训练数据集

$$T=\{ (x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}$$
$$x_n=(x_n^{(1)},x_n^{(2)},...,x_n^{(n)})$$
由$P(X,Y)$独立同分布产生。
# 基本方法
朴素贝叶斯通过训练数据集学习联合概率分布$P(X,Y)$.具体地，学习先验概率分布及条件概率分布。

*先验概率分布*
$$P(Y=c_k),k=1,2,3,...,K$$
*条件概率分布*
$$P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},X^{(2)}=x^{(2)},...,X^{(n)}=x^{(n)}|Y=c_k),k=1,2,3,...,K$$
注意：这里$c_k\epsilon set(lable).$  
朴素贝叶斯法对条件概率分布作了条件独立性的假设。具体地，条件独立性假设是
$$P(X=x|Y=c_k)=\prod_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k)$$
那么，根据贝叶斯定理
$$P(Y=c_k|X=x)=\frac{P(Y=c_k) \prod_{j=1}P(X^{(j)}=x^{(j)}|Y=c_k)}{\sum P(Y=c_k) \prod_{j=1}P(X^{(j)}=x^{(j)}|Y=c_k)},k=1,2,3,...,K.$$
故
$$y=f(x)=arg max_{c_k}\frac{P(Y=c_k) \prod_{j=1}P(X^{(j)}=x^{(j)}|Y=c_k)}{\sum P(Y=c_k) \prod_{j=1}P(X^{(j)}=x^{(j)}|Y=c_k)}$$
注意到，分母为1，故
$$y=arg max_{c_k}P(Y=c_k) \prod_{j=1}P(X^{(j)}=x^{(j)}|Y=c_k)$$

# 进阶

## 高斯朴素贝叶斯
高斯朴素贝叶斯(Gaussian Naive Bayes),高斯朴素贝叶斯算法假设所有特征都具有高斯分布(正态/钟形曲线)。这适用于连续数据，例如日温度，高度。

